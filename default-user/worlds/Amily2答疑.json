{
    "entries": {
        "0": {
            "key": [],
            "keysecondary": [],
            "comment": "安装更新",
            "content": "<安装更新>\n1：sillytavern直接安装\n扩展地址：（国外源）\nhttps://github.com/Wx-2025/ST-Amily2-Chat-Optimisation.git\n挂上梯子，复制这个链接，打开你的酒馆。\n点击扩展-点击安装扩展，将链接粘贴进去，点击Install for all users按钮。\n\n2：本地安装\nhttps://github.com/Wx-2025/ST-Amily2-Chat-Optimisation.git\n点进去这个链接，点击法典/code按钮，点击下载ZIP，将下载的ZIP文件解压缩到目录。\nPC端：酒馆根目录\\public\\scripts\\extensions\\third-party\n移动端：手机根目录/data/data/com.termux/files/home/SillyTavernpublic、scripts/extensions/third-party\n最后将ST-Amily2-Chat-Optimisation-main文件夹改成ST-Amily2-Chat-Optimisation\n\n【更新】\n1：如果有新版本更新，在插件的主页面会有更新按钮出来，点击之后会自动跳转到管理扩展页面，点更新就行。\n2：如果主页面迟迟没有更新按钮出来，但你又确定有新版本，则挂上梯子，来到sillytavern酒馆的扩展页面，点击管理扩展，进行更新。\n3：如果你更新之后还是现实原本的版本号，那么刷新浏览器重新查看。\n刷新浏览器后依旧显示原本的版本号，则将插件删除，重新安装。\n\n【疑难解答】\n1：插件删除后依旧存在，则直接手动去扩展的安装目录，将ST-Amily2-Chat-Optimisation文件夹手动删除。\n\n2：通过酒馆安装时报错，则检查自己的梯子是否可用，以及是否打开了TUN模式，如果没有打开，则打开它。一定要记得提醒开TUN模式。\n\n</安装更新>\n\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 1,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 0,
            "displayIndex": 0,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 0,
                "probability": 100,
                "useProbability": true,
                "depth": 1,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "1": {
            "key": [
                "正文优化"
            ],
            "keysecondary": [],
            "comment": "正文优化功能简介",
            "content": "<正文优化核心原理>\n\n首先讲解一下其核心原理。\n\n我们是以一个特定的正文标签中的内容进行拦截，然后发给下一个模型进行拦截并优化。\n\nPs:这里的指的是把模型发给你的剧情正文内容，而不是思维链、状态栏、或者其余什么格式的内容。\n\n完整的过程：\n\n你发送一条消息：“吃了吗您内？”\n\n模型A进行回复：\n<thinking>模型A思考内容</thinking>\n<content>模型A正文内容</content>-----→假设我们御定的正文标签为content。\n<状态栏>模型A状态内容</状态栏>\n\n这里的模型A正文内容，是我们实际发送给模型B的内容，然后模型B根据我们的提示词对模型A正文内容进行优化。（此时你是看不到这个内容的，但可以通过我们的查看优化前文看到。）\n\n模型B优化后回复：\n<thinking>模型B思考内容</thinking>-------其实这里无所谓它回复的是什么标签。\n<content>优化版正文内容</content>-------这里的优化版正文内容就是我们需要的。\n<状态栏>模型B状态内容</状态栏>-------这里是什么其实也无所谓。\n\n我们的扩展进行一系列你看不到的方式自动替换文本后，你最终收到的消息：\n<thinking>模型A思考内容</thinking>\n<content>优化版正文内容</content>\n<状态栏>模型A状态内容</状态栏>\n\n优化的目的，就是将一些模型会经常出现的一些固定语式和词汇，让它换一种说法。\n<--\n比如说，优化前模型会经常性的投石子、神化、绝望、淬毒刀、名为xx…此刻xx…这种固定的词汇句式。\n我们让模型B进行优化，但是又不让剧情发生变化，以及不让语句变得不通顺，在此基础上进行优化。\n→\n\n像是预设/世界书是从起点出发，他们的原理是给主模型输出一堆设定，让它遵循设定不进行输出固定的语式。\n但模型一般超过了一定tokens之后，就会出现完全不遵循规定的行为，俗称（流口水）。\n而还有一个特例，就是正则杀八股，正则的原理就是，将经常出现的固定名字删除掉，让ai去读上下文的时候。\n读不到“石子”这样的词。好处是你必定看不到“石子”，坏处是模型依然会输出，且你还知道它一定输出了。\n因为当你看见“内心如同**落入心湖，轰的一声，泛起了一层层的**”，尽管你看不见**到底是什么，但是你绝对也知道这个**是石子（邪笑~），所以正则杀八股，也只不过是“自慰”行为罢了。\n\n而我们的插件做法：\n等模型去随意输出，哪怕你去流口水了，我们还有第二个模型进行改动，让句子通顺的同时，把石子干掉，把文风优化，把八股干掉。\n\n当然也存在一些硬伤，因为我们需要第二次调用api，所以时间会延长个十几秒。但换来的是绝对的，文风上的超级优化，哈八股的绝对消失。并且在此过程，还可以提升语言、视觉的流畅度（逗号增值、省略增值、段落缩进等），而且只要你提示词写得好，模型B可以根据你的想法随意去改内容。\n\n</正文优化核心原理>\n\n",
            "constant": false,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 12,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 1,
            "displayIndex": 1,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 1,
                "probability": 100,
                "useProbability": true,
                "depth": 12,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "2": {
            "key": [],
            "keysecondary": [],
            "comment": "正文优化使用方法",
            "content": "<正文优化使用方法>\n操作流程：\n一、设定优化标签\n二、选择优化模式\n三、编辑提示词（只是介绍，不用动）\n四、开启查看优化前正文功能\n五、启动并尝试优化！\n六、预设标签优化拟合\n\n优化标签设定：\n首先正文内容必须要被标签包裹，大部分酒馆预设条目里会有相应的设定，若预设中没有则需自己在预设中添加。\n- 例如：content\n- 注意：填写时只需要填写字母，不需要输入<>进行包裹。也不需要填写闭合标签。\n为了防小白这里简单说一下，一般预设中关于 “字数”、“正文”相关的条目中会附带正文包裹标签例如：\n\n- 正文字数需求：2000 - 30000token（以\"<content>\"标签的内容为准）\n- **正文使用语言：zh-CN**\n- **正文内容用\"<content>\" 这里是正文 \"</content>\" 包裹**\n\n<content>就是正文的包裹标签，不同预设可能使用的包裹标签不一样，因此你需要把标签设置到优化里面，不需要<>，你的正文是什么标签包裹就填什么标签。\n\n拓展内已经默认自带了对应的提示词，正常情况不需要动他，这里是留给对提示词有一定了解的人使用的，正常来说只需要关注 “预设提示词(任务规则)” 。\n\n目前内置的提示词已经可以做到“去除八股”、“优化比喻”、“文风润色”，若需要更多功能或者对默认的提示词效果不满意可以自行修改，这里不做修改教学，修改后记得 “保存” 即可，也可以一键 “恢复默认” 。\n</正文优化使用方法>\n\n【正文优化功能疑难解答】\n\n1：为什么我开启了正文优化功能，但是无效？\n\n排查问题流程：\n- 第一步是查看你的正文标签是否是正确的。\nA：点击小铅笔，看看你的正文是用什么标签包裹的，是否与插件设置的标签一致。\nB：A排除后，点击插件主页面的测试并修复，如果显示`命令检查器未检测到需要修复的问题`，那么标签设置依然不对。\nC：如果显示修复完成，那么代表手动优化是完成了的，代表标签设置没有任何问题。则先关掉所有的正则，再去发送一条消息进行测试。\n\n- 完成第一步之后，依旧无法优化，则进行内容排除，将正文中的无用内容排除一遍。其次将预设提示词（任务规则）恢复一下默认。\n\n需注意：无感优化需要关闭流失传输。刷新优化无需关闭流式传输。\n\n经常性不优化，但偶尔优化，则检查自己的api是否足够稳定，如果不够稳定，则将模型切换为flash。\n\n---\n\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 2,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 2,
            "displayIndex": 2,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 2,
                "probability": 100,
                "useProbability": true,
                "depth": 2,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "3": {
            "key": [
                "微言录",
                "小总结"
            ],
            "keysecondary": [],
            "comment": "微言录小总结功能简介",
            "content": "<微言录小总结功能简介>\n\n微言录、俗称小总结。但与原本的总结姬并不一样。\n\n简单解释一下，就是因为楼层太高，而导致tokens太多，模型完全不知道哪是哪，然后就会变得智障起来。\n\n通常的解决方案就是隐藏楼层解决，但是如果隐藏了，模型就会忘记之前的内容，所以就将之前的内容进行一次总结，然后自动写进世界书里面，让聊天记录不占tokens的同时，还不会遗忘掉以前的内容。\n\n<微言录小总结功能简介>",
            "constant": false,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 13,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 3,
            "displayIndex": 3,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 3,
                "probability": 100,
                "useProbability": true,
                "depth": 13,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "4": {
            "key": [],
            "keysecondary": [],
            "comment": "微言录小总结使用方法",
            "content": "<微言录小总结使用方法>\n前置设置：\n先回到拓展的“主殿”（就是首页），在“世界书档案司与律法”进行设置。\n写入主世界书：\n\t比如总结会写进卡自带的世界书\n\n写入独立存档：\n\t会新建一个“Amily2-Lore-char-这里是卡片名称”的世界书。（总结成功才会出现的，具体名称可能后续会因更新改变，但大几率作者并不会去动它）\n\n蓝灯绿灯插入深度：\n\t推荐设置为蓝灯（保持开启），绿灯会导致需要出发关键词，主模型才会读取。深度一般设置为2\n\n确认敕令：\n\t就是个保存，修改后随手点一下它（虽说自动保存的，但是养个好习惯）\n\n使用方法：\n先设置“正文抓取标签”并启动“标签提取按钮”（标签设置和优化功能的标签设置方式一样，并且推荐只去提取包含时间的标签+包含正文的标签。并且去主动排除掉不必要的内容）\n\n\n手动总结（手动熔铸范围）：\n可以手动输入想要总结的层数范围，然后点击“熔铸”。（想总结哪里你说了算）\n\n\n自动总结：\n把未总结过的楼层按顺序进行总结。功能较多名字开始有点不适应的按照这个教程顺序设置即可。\n\n远征阈值：\n这里同时关联两个功能：\n自动触发总结的层数：如设置50，聊天达到50层自动触发总结，总结50层。\n单批次总结的层数：如设置50，若你有200层聊天，会分4批次进行总结，每批次总结50层。\n写入史册：\n就是写进世界书，写进那个世界书由“前置设置-世界书档案司与律法”确定。\n自动巡录：\n就是自动总结的开关，远征阈值设置了多少，到达了对应层数自动触发总结。\n（默认保留两层不去总结，比如说达到22层聊天记录的时候，才会总结前20层）\n开始远征：\n这是给已经有“大量聊天层数”使用的，点击后按照“阈值”进行分批次总结。\n\n【阈值】：例如设置的是30，那么100层楼就会被分为30+30+30+10被送去总结。\n【存入翰林院】：每次自动总结或者远征都会将小总结的内容自动送去向量化。（不推荐，更推荐使用`将前段的大总结内容自动送去向量化`功能，但如果你喜欢，也可以。向量化之后我更推荐你手动将小总结设置为绿灯条目，或者手动删除已经完成的小总结。）\n\n【疑难解答】：\n- 小总结出来的内容根本不对，或者变成了正文的续写？\n1：模型抽风了，换个模型。或者就是你没有设置好内容的排除。\n- 小总结内容太多了，这正常吗？\n2：这很正常，模型gemini-2.5-Flash基本分不清什么是重点，会认为越详细越好，换成gemini-2.5-pro基本每次小总结都是保持在20多条左右，而模型DSv3是最精简的。\n\nPs：如果有人问你，小总结之后要启动这个条目吗？世界书要绑定角色卡吗？直接使用我的原话回答他！\n\n“你tm的你不绑定到角色卡，你不启用总结的条目，那你总结个懒子？养眼吗？”\n\n（哪怕向量化了小总结，我也推荐启动原小总结条目，大总结除外。）",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 3,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 4,
            "displayIndex": 4,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 4,
                "probability": 100,
                "useProbability": true,
                "depth": 3,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "5": {
            "key": [],
            "keysecondary": [],
            "comment": "宏史卷大总结使用方法",
            "content": "<宏史卷大总结使用方法>\n\n宏史卷，即大总结，位于“内阁密室”栏目底部。\n\n前文提到的微言总结将一段历史记录总结为了一个个小事件并用“权重值”体现了每个小事件的重要性。\n\n宏史总结则是将一系列的小事件，如同小说章回一般精炼，突出权重高的重要事件，合并甚至省略权重低的小事，并总结出其中的伏笔与展望以供后续使用。\n\n\n这个大总结并不是“对正文”进行大总结，而是“对小总结”进行优化总结为：“章节小说”\n\n【使用方法】：拉到内阁密室的底部，选择你要进行总结的世界书条目`【敕史局】对话流水总账`，点击精炼既可。\n\n【疑难解答】：\n- 缺少流水金印怎么办？\n\n1：一般情况下，小总结完成之后，在底部会出现一条内容，`本条勿动【前X楼总结已完成】否则后续总结无法进行。`\n这个就是流水金印了，保持在底部。\n\n2：另外选择的条目必须为`【敕史局】对话流水总账`\n\n- 将前段大总结自动送去向量化是什么意思？\n\n1：很简单，例如说，你现在进行大总结的楼层是400-600层的小总结。那么开启这个开关后，会将1-400楼的大总结内容自动送去向量化，并以特定的标注替换原本文本。\n\n2：最后将400-600楼的大总结，保留在世界书中，以保证最近的剧情始终连贯。\n\n</宏史卷大总结使用方法>",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 4,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 5,
            "displayIndex": 5,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 5,
                "probability": 100,
                "useProbability": true,
                "depth": 4,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "6": {
            "key": [],
            "keysecondary": [],
            "comment": "功能总览",
            "content": "# **功能列表**：\n`正文优化`、`大小总结`、`记忆表格`、`rag向量`、`剧情推进`、`隐藏楼层`、`提示词查看器`。\n\n- 正文优化：后台自动杀八股、杀神化、杀绝望，改善文风。（位于插件的主页面）\n   * 功能优势：首发，目前此功能只有我这里有，且比正则杀八股、预设防八股等方式更加彻底、体验感更好。\n   * 辅助功能：优化前文查看器，可随时查看在优化之前的原始文本是什么样子的，方便对比效果。\n\n- 自动总结：实现将聊天自动整合总结写进世界书。（位于内阁密室子页面）\n  * 小总结：后台自动将聊天记录总结并写进世界书。\n  * 大总结：负责将小总结二次精简，避免小总结冗余。\n  * 功能优势：标签提取与内容排除规则，使总结更加精准、详细。且可自动保留最近的总结，将之前的总结送去向量化。\n\n- 记忆表格：将重要细节转化为表格形式进行记录，并自动发送给大模型。（位于内存储司子页面）\n   * 原始填表：使用酒馆主模型进行读表与填表。\n   * 分步填表/兼容优化：使用插件模型进行填表，且与正文优化功能兼容。\n   * 功能优势：对于表格的自定义更加方便快捷、分步与立即填表等可选择条目读世界书、上下文。完善了旧卡也可**【一键立即填表、选择楼层填表、漏填后可当前楼层填表的容错、使用小总结的标签提取、内容排除规则、冗长表格一键重新整理】**等优化使用体验的功能。且所有功能基本都是一键式操作。\n\n- rag向量：向量、重排序，聊天中自动检索出相关的剧情内容发送给主模型，提高记忆与剧情关联性。（位于翰林学院子页面）\n   * 功能优势：混合api的方式，无需切换api，提供**【聊天记录、手动录入、世界书录入、整本小说】**四种向量化方式，懂得无需多解释，不懂的解释也说不清楚。\n\n- 剧情推进：实现在你发送消息时，自动读取世界书条目与上下文，向api发送请求，剧情自动推进，再也不需要什么剧情推进的预设了。（位于剧情优化子页面）\n  * 功能优势：四种推进变量，不仅仅可以推进，而且可控。另外还有平行事件的诞生，使得剧情更加丰富。\n\n- 自动隐藏楼层：这东西还需要解释吗？（位于内阁密室子页面）\n\n- 提示词查看【密折司】：开启后可查看到所有发送给主模型的内容。（位于聊天页面左下角魔法棒扩展）\n   * 功能优势：提供总览与分条目的tokens统计与字数统计，且有小图标标注出来表格与rag向量化的注入位置（仅Amily2号助手插件的表格与rag向量有效。）",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 5,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 6,
            "displayIndex": 6,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 6,
                "probability": 100,
                "useProbability": true,
                "depth": 5,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "7": {
            "key": [],
            "keysecondary": [],
            "comment": "翰林院rag向量化使用方法",
            "content": "<翰林院rag向量化使用方法>\n翰林院 (RAG 向量化) 使用指南\n核心概念：翰林院是做什么的？\n简单来说，翰林院（或者说 RAG 向量化）的作用就是给你的 AI 一个外部记忆库。\n很多人问向量化到底有什么用？答案就是：将 AI 一次性“吃”不下的长篇内容（比如几十万、几百万字的小说背景、详细的人物设定），转化为它能理解的“记忆地标”（向量）。当你发送消息时，系统会自动检索这些地标，找到最相关的内容，然后悄悄递给 AI，让它“回忆起”这段剧情或设定。\n这样，你的 AI 就能拥有超长期的、永不磨灭的记忆了。\n\n\n一、初次使用：API 设置（前置步骤）\n向量化需要专门的“神力”（Embedding API）来支持。如果你没有，或者“神力测试”失败，请按以下步骤操作。\n注册 API 服务：\n我们推荐使用硅基流动 (SiliconFlow)。这是一个提供包含 Embedding 模型的服务商，同时也提供后续会讲到的 Rerank 服务。\n硅基流动端点：https://api.siliconflow.cn/v1\n获取 API 密钥：\n注册并登录后，在你的账户中找到 API 密钥 (API Key) 并复制它。\n在翰林院中配置：\n回到酒馆的翰林院设置界面，点击 忆识检索 标签页。\nAPI 设定：选择 自定义。\n通行令牌 (API Key)：粘贴你刚刚复制的密钥。\n嵌入模型：点击 获取模型，然后选择一个可用的模型。\n测试神力：点击此按钮。如果提示“神力充沛”，说明配置成功！\n​\n重要提示：翰林院的 API 和主界面聊天的 API 是完全独立的。这里设置的只负责记忆、检索、注入，与优化总结等并不关联。\n​\n\n二、标准工作流程：如何安全地管理记忆库\n为了防止因切换角色而导致记忆库错乱或数据丢失，请务必遵循以下锁定会话的工作流程。\n\n（当然，如果你心大，用不用这套流程也无所谓。）\n选择目标角色：\n在酒馆主界面，选择你想要为其添加或管理记忆的角色卡。\n进行向量化操作：\n进入翰林院，使用下文介绍的任何一种方式录入记忆（如凝识聊天、导入小说等）。\n确认并锁定：\n操作完成后，在翰林院顶部的状态区，点击 刷新 按钮（🔄）确认“忆识总数”已增加。然后，点击锁定会话 按钮。按钮会变为“解锁会话”状态。\n安全切换：\n现在，你可以安全地切换到任何其他角色卡进行聊天，而不必担心会影响到刚刚锁定的那个记忆库。（此步骤应该需要先关掉总开关，不过我没有尝试过在向量化途中去聊天。）\n需要再次编辑时：\n如果你想为被锁定的角色继续添加记忆，必须先切回该角色卡，然后在翰林院点击 解锁会话 按钮，再重复步骤2和3。\n一句话总结：要动哪个角色的记忆库，就先切到哪个角色，操作完立刻锁定，万无一失。\n\n三、核心功能：如何录入记忆？\n翰林院提供了多种方式，将你的知识录入“忆识宝库”。\n1. 凝识聊天记录\n这是最常用的功能，可以将你和 AI 的对话直接转化为长期记忆。\n智能记录：翰林院会自动记录上次凝识到的楼层，你无需手动记忆。\n范围设置：在“凝识范围”中，将结束楼层设为 0，即可自动处理从起始楼层到当前所有的最新对话。\n安全操作：强烈建议在点击“开始凝识”前，先点击“预览内容”，检查将要被向量化的文本是否正确。\n2. 整本录入 (小说/文档)\n这是一个强大的功能，可以让你将一整本小说（.txt格式）直接录入记忆库。\n选择文件：点击“选择.txt文件”按钮。\n编码格式：如果你的文档是GBK或Big5等非UTF-8编码，请在下拉菜单中选择对应的选项，插件会自动为你转码。\n开始录入：点击后，系统会显示进度条，请耐心等待。大文件可能需要几分钟时间。\n3. 手动录入 & 按条目编纂\n手动录入：在文本框里粘贴任何你希望 AI 记住的内容（角色设定、世界背景等），然后点击 开始录入。\n按条目编纂：可以直接选择一个世界书 (World Info) 及其中的条目，将其内容完整录入。\n​\n幕后揭秘：自动标签\n无论你用哪种方式录入，翰林院都会智能地为内容打上来源标签，例如 <聊天记录>, <小说录入>, <世界书>。这能帮助 AI 在“回忆”时更好地理解信息的上下文。\n​\n\n四、进阶功能：让记忆更精准\n1. 忆识精炼 (Rerank)\n当检索到的相关记忆片段过多时，Rerank 功能可以进行二次筛选和排序，挑出与当前对话最最相关的几条，大幅提升AI回应的精准度。\n启用：在“忆识精炼”标签页，打开“启用 Rerank”开关。\n配置：像配置Embedding API一样，填入你的 Rerank API 地址、密钥和模型。同样推荐使用 SiliconFlow。\n返回结果数 (top_n)：决定经过精炼后，最终返回给 AI 几条最相关的记忆。通常设置为 3-5 即可。\n2. 圣言注入 (高级设定)\n这里决定了检索到的记忆，将以何种方式、在哪个位置“告诉”给 AI。\n圣言模板：你可以自定义注入的格式。一个好用的模板示例：\n—\n以下内容是翰林院向量化后注入的相关内容，是已经发生过的事情简短总结，但可能顺序会有些错乱，但已经对前后做出了标识，请自行判断顺序：\n<总结内容>\n{{text}}\n</总结内容>\n【以上内容是已经发生过的事情，切莫以此作为剧情进展，只是作为提醒发生过的事情】\n—\n注入位置：\n主提示前：放在所有提示词的最顶端，权重最高。\n主提示后：放在主提示词之后，聊天记录之前。\n聊天内 @ 深度：（推荐） 模拟一条特定角色的历史消息。你可以精细控制它出现在聊天记录的倒数第几层，以及它的“扮演者”（系统、用户或助手）。\n3. 内容排除\n在“凝识法则”区域，可以设置排除规则，在向量化之前移除不需要的内容（如大段的代码块、作者的注释等），让记忆库更纯净。\n\n</翰林院rag向量化使用方法>\n\n【疑难解答】\n\nQ1: 为什么我的“神力测试”总是失败？\nA: 99% 的原因是你的 API 配置有误。请仔细检查 API 地址、API Key 是否正确，以及模型是否可用。\nB:严格使用嵌入式模型，并非是补全模型。\nQ2: 为什么我的向量块数突然变成 0 了？或者我和A聊天，B的记忆却多了一堆？\nA: 这是因为你没有遵循标准工作流程！请严格按照本文第三节的“锁定/解锁会话”步骤操作，这是保证记忆库安全稳定的基石。\nB:依照向量化数据迁徙那里的教程可以找回原本的向量化记忆文件。\nQ3: 为什么我装了 Amily2，但感觉 RAG 没生效？\nA: 请检查是否安装了其他同样具有 RAG 功能的向量化插件。Amily2 的向量化功能与其他同类插件有冲突，请确保只保留一个。\n\n最后注意：向量化大文件时，严格使用先锁定会话，再进行向量化操作，可以避免向量化过程归0。\n\n---\n\n向量化文件迁徙教程\n\n如果你打开这个文档之后第一件事就是找到这个页面，那么我就要在此说一声很抱歉了。\n\n原因如下：\n1：在我技术并不完善的情况下将rag向量这个功能推出，给你带来了不便。\n\n2：旧版本中偶尔间出现的向量化数据归0，并不是你的操作问题，而是我们向量化的漏洞。\n\n所以针对以上，进行了一番完善的操作,此次之后，向量化再也不会被归0了。\n\n——我们只需要麻烦这一次！\n\n\n\n\n先不多说，我先将向量化数据迁徙的教程呈上：\n\n第一：\n让我们打开酒馆根目录，也就是sillytavern-[某个版本后缀]\n\n此项需要注意的地方就是，PC端可能比较好找，我就不再多说，但是移动端可能你会找不到，所以请移动端请打开你的MT管理器（或者可查看手机根目录的文件管理器）\n\n第二：\nPC端打开文件地址： 酒馆根目录\\data\\default-user\\vectors\\webllm \n安卓端文件地址：从手机根目录出发/data/data/com.termux/files/home/SillyTavern/data/default-user/vectors/webllm\n\n依次打开之后，你会看到类似的文件夹：\n\nchar_1_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms\n也就是char_1以数字开头的为旧向量化的文件夹。\n\nchar_仙逆_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms\n而char_仙逆以角色卡名字为开头的，是新向量化数据文件夹。\n\n我们需要做的就是，将旧的向量化数据文件夹打开：\nchar_1_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms/undefined/index.json\n这个index.json就是我们需要的文件。\n\n然后复制它，将它覆盖并替换新的向量化数据文件夹中：\nchar_仙逆_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms/undefined/index.json\n\n此操作执行完成后，你的向量化数据就相当于是迁徙完成了，且此文件，可以替换到任意一个角色卡中。\n\n也就是说，当你向量化了一整本小说甚至说更大的文件，需要耗时巨长。那么你也不需要进行二次向量化，而是直接将其覆盖替换为你需要向量化的角色卡中，同样是可以使用的。\n\n\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 6,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 7,
            "displayIndex": 7,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 7,
                "probability": 100,
                "useProbability": true,
                "depth": 6,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "8": {
            "key": [],
            "keysecondary": [],
            "comment": "api连接配置",
            "content": "<各种api报错>\nPs:这里的问题是最多的，一定要去重点解答！\n注：关于API的设置该插件有三个地方需要填写分别是：优化总结、向量化、Rerank\n第一：主殿API与模型配置\n所处位置：点击插件后，第一个页面的里面。\n\n此处的api配置所管辖区域为：正文优化、微言录小总结、宏史卷大总结、表格、剧情优化。\n配置参考：最大Token数: 65000、思考活跃度: 1.2、上下文参考数: 2\n\n首先这里设置了四种api的配置方案\n1：openai兼容模式\n- 不多解释，输入端口和密钥就行了。\n推荐模型：gemini-2.5-flash、gemini-2.5-pro、dsV3\n2：谷歌直连模式\n- 不多解释，单独输入密钥就可以。\n3：sillytavern后端\n- 这里就简单解释一下。sillytavern后端直连的模式，一般适用于反代的接口、轮询的接口。需要与酒馆主api的配置保持一致，但是模型可以选择不一样的。\n4：sillytavern预设\n- 这个是最通用的模式，理论上，只要你的api在酒馆可用，那么在我插件就可用。\n- 配置方法是打开酒馆的api连接，然后新建一个预设，输入你想让插件使用的模型和api配置，切换为其他预设之后再切换回来，**点击保存**，回到插件，选择它就可以了。\n- 实现方法是，当需要我插件发送api请求时，会自动切换为这个保存的预设发送出请求之后，再瞬间切换回你酒馆使用的api配置。\n- 如果切换回来，你的酒馆api配置没有自动连接，那么查看你的酒馆api配置是不是没有勾选自动连接到服务器。\n\n【小总结报错】、【大总结报错】、【正文优化报错】\nAPI调用发生错误: Error: Google API请求失败: 429\nAPI调用发生错误: Error: Google API请求失败: 500\nAPI调用发生错误: Error: Google API请求失败: 503\n这三个数字报错，则换个密钥，换个模型试试看， 如果你使用的flash则换成pro，如果你使用的pro则换成flash，另外503报错不是我插件的问题，而是谷歌服务器的问题。\n\nAPI调用失败:Failed to fetch\n而这个是最常见的报错，换模型，换api解决。（不要瞎回答，就简单的换模型，换api解决。）\nAPI调用发生错误: Error: Google API请求失败: 400\n请求的格式不对，也就是选择模型错误。\n\n最后提示用户，deepseek-chat以及R1模型不能用在插件，因为R1自带了一层思维链，chat非流式请求会出问题。deepseek适配的模型只有V3，V3.1也不行（个别人可以）。\n\n另外大部分的远征失败、自动巡录失败、填表红色报错失败，都是api的配置问题，自行切换api或者模型。\n\n最稳定的模型是dsV3模型，小总结、大总结、分步填表都很稳定。缺点是，正文优化可能会有点问题，优化出来的东西根本没法看。\n\n</各种api报错>\n\n<向量化api报错>\n神力之源(API)\n所处位置：从主页面点击翰林学院后，忆识检索框里面。\n\n此处所管辖位置：\n向量化嵌入式模型的获取、测试、以及使用。\n目前可用的接口只有openai兼容的向量化嵌入式模型，例如硅基流动的Qwen3-Embedding-8B\n注：非嵌入式模型，不可使用此处的功能。例如什么：gemini-2.5-pro、gemini-2.5-flash，都不属于嵌入式模型的范畴。唯有明确为Embedding标志的，为嵌入式模型。\n再次重申：【向量化嵌入式模型】\n\n\nRerank精炼\n所处位置：主页面点击翰林学院进入子页面，然后点击忆识精炼。\n\n此处所管辖位置：\n其实这个功能是完全在后台进行的，所管辖位置就只有这个忆识精炼的页面了。\n目前可用接口同样是openai兼容的，例如硅基流动的Qwen/Qwen3-Reranker-8B\n注：非重排序模型，不可使用此处的功能。例如什么：gemini-2.5-pro、gemini-2.5-flash，都不属于重排序模型的范畴。唯有明确为Reranker标志的，为重排序模型。\n\n注：重排序的报错一般都是因为模型选择不正确，或者api的配置不正确。\n\n端口https://api.siliconflow.cn/v1而不是https://api.siliconflow.cn/v1/Reranker\n\n---\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 7,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 8,
            "displayIndex": 8,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 8,
                "probability": 100,
                "useProbability": true,
                "depth": 7,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "9": {
            "key": [],
            "keysecondary": [],
            "comment": "表格问题答疑",
            "content": "<表格简介>\n填表模式：\n\t原始：就是“聊天同时填表”，走的酒馆主API，例如输出正文后还得等它写一大堆填表内容，你才能继续输入；原始填表目前兼容“正文优化”功能\n\t分步：就是“独立填表”，使用的插件配置的api，分步填表目前不兼容“正文优化”功能\n\t兼容优化：这玩意不就是“独立填表+正文优化”同时进行。兼容优化目前兼容“正文优化”功能。使用的是插件的api。\n\n可控操作：点击列名可以左加列、右加列、左移动列，右移动列、编辑列名、删除列。\n点击行名可以上下移动行，上下添加行、删除行。\n\n立即填表：根据批处理阈值的数字分批次进行填表，与微言录的操作一致，并且使用的也是微言录的标签提取与内容排除规则。\n选择楼层填表：与立即填表一样，不过可选楼层。\n填当前楼层：如果你的填表，本楼被漏掉了，可以点击这个按钮，与立即的规则一样，不过发给api的只有本层楼的内容。\n重新整理：当表格内容过多时，可以点击这个按钮，将当前表格发送给插件的api进行重新整理精简。\n</表格简介>\n\n【疑难解答】\n\n- 为什么表格不会自动填表？\n\n首先用户是使用的哪个填表模式，然后根据以下内容进行解答：\n如果使用的是原始填表，那么先进行一下配置：\n1：聊天内\n2：深度0\n3：系统\n\n确认两个开关以及选择的模式是对的。\n接着发送一条消息出去，点击ai回复消息的小铅笔，检查是否存在<Amily2Edit>标签。\n\n如果有，且内容与我的类似，那么就是填表成功了。\n\n如果没有，去你的预设提示词里面添加格式：\n<Amily2Edit>\n<!--\n(这里是你的填表内容)\n-->\n</Amily2Edit>\n\n一般都在你预设的cot思维链附近的格式检查、最终输出格式那个地方，自行添加进去。\n\n当然也有更简单的方法，直接发送一条消息出去：\n“记得填表，现在的填表标签是<Amily2Edit>”\n\n这一般能解决你这单独一个角色卡不填表的问题，一劳永逸的方法还是让预设去适配我的填表标签。\n\n\n另外如果你使用的分步填表，不要去开正文优化！\n\n如果你想用正文优化，也想用分步填表，选择兼容优化这个填表模式。\n\n另外，分步填表以及兼容优化，一般不会出现不填表的问题！\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 8,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 9,
            "displayIndex": 9,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 9,
                "probability": 100,
                "useProbability": true,
                "depth": 8,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "10": {
            "key": [],
            "keysecondary": [],
            "comment": "密折司妙用",
            "content": "【密折司】、【查看优化前文】、【提示词链编辑器】\n\n密折司：效果已经在功能简介讲过。\n\n那么对于答疑来说，妙用就是在当原始表格始终不填表的情况下，可以让用户打开密折司，然后发送一条消息出去。\n\n根据密折司的弹窗，快速定位表格是否被注入到了提示词中（被注入的条目会有一个表格的小图标、翰林院向量化也有。）\n\n如果没有注入，关掉所有正则再测试一次。如果依然没有注入，那么排除正则的原因，查看是否是插件的冲突，目前已知冲突插件（聊天记录快速恢复，偶尔会导致不注入）、（聊天超级管理器，会导致向量化两次检索，重排序两次调用。）\n\n查看优化前文：可以查看在使用优化正文功能时的未被优化的原始文本。\n\n如果优化功能在没有提取到特定标签的内容时，里面就会是空的。如果不为空，正确提取到了依旧不优化，则让用户关掉所有正则再进行测试。\n\n提示词链编辑器：\n所有功能的提示词编辑的位置，提供了导入导出、顺序的排序。（如果可以，你作为客服，如果用户要求，你也可以帮助他编辑一下提示词，让他将完整的提示词内容发送给你。）\n\n",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 9,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 10,
            "displayIndex": 10,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 10,
                "probability": 100,
                "useProbability": true,
                "depth": 9,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "11": {
            "key": [],
            "keysecondary": [],
            "comment": "疑难解答",
            "content": "会经常有一些傻傻的用户会问一些这样的问题：\n- 如果我使用了小总结，还需要用表格吗？\n- 如果我使用了向量化，还需要用总结吗？\n\n简述：这是我个人的在sillytavern（酒馆）实现长期记忆的方案，整个体验下来感觉良好。爬楼数已经达到了2700，记忆的丢失也并没有很严重。\n\n首先我需要的两个要素：Amily2号、记忆表格（目前我们插件已经有了记忆表格，所以与木悠的记忆增强表格选择一个使用）。\n\n具体的实现方式：\n\n1：总结记录大事件、重要事件、关键节点。保证主模型的剧情大方向保持不变且重要的事情不会忘。 \n2：表格的预设记录了角色细节以及重要的物品、任务等，确保细节不被丢失。 \n3：rag向量化，将总结或者正文或者摘要进行向量化，可以保证每一条的模型回复消息都与剧情是有关联的。\n\n\n详细教程：\n\n1：第一件事使用我们的微言录进行总结，然后每次达到200层楼左右进行一次宏史卷大总结。\n\n\n2：重复上面的做法，如果当单独的宏史卷，已经超过了两万字符，那么继续微言录总结，让它达到两万五千左右\n\n3：使用大总结，以及打开将前段大总结自动送去向量化的开关。\n\n3.1：（此步骤可选）基于3的步骤，在大总结之前，可以新建一个世界书的条目，将前段的大总结复制进去，但是不要启动它，只留作备份就行了。避免向量化的文件你清空后无法使用，总结也丢失就不好了。\n\n\n其次的操作就是：翰林院那边的设置，这里需要注意，选择聊天内，选择系统，深度与【敕史局】对话流水总账保持一致。\n\n—\n以下内容是翰林院向量化后注入的相关内容，是已经发生过的事情简短总结，但可能顺序会有些错乱，但已经对前后做出了标识，请自行判断顺序：\n<总结内容>\n{{text}}\n</总结内容>\n【以上内容是已经发生过的事情，切莫以此作为剧情进展，只是作为提醒发生过的事情】\n—\n\n5：走到这一步其实你已经完成了大部分的长期记忆设置，但是这样可能会丢失一些长期记忆的细节。\n\n所以我们需要一个进行记录细节问题——记忆表格。\n\n不需要它进行记录什么重要事件、关键节点、大小总结什么的，因为我们的总结已经完全做到了这一点。\n\n所以我们需要让它记录的东西就只有这些角色信息、任务、物品之类的，我们的表格默认预设已经完美解决了这一点。\n\n注意：目前我们的插件已经内置了表格，看你更喜欢用哪个表格，只开一个表格就可以了。\n\nOK，到这里你已经完成了所有长期记忆的步骤，起码我能保证的一点就是，在一千楼之内，不会丢失任何记忆。（目前我2700楼都感觉良好。）\n\n最好将世界书的总结条目，与向量化的注入位置，设置成一样的。\n\n完成注入之后，向量化的内容直接衔接到了我们微言录、宏史卷的世界书总结前面！\n\n也就是说，当没有注入的时候，这个总结记录的是后半部分的楼层内容，前半部分是缺失的。\n\n现在我们向量化注入之后，闪回的记忆碎片（而且是有关联的碎片）被放在了缺失的记忆那里！",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 10,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 11,
            "displayIndex": 11,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 11,
                "probability": 100,
                "useProbability": true,
                "depth": 10,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "12": {
            "key": [],
            "keysecondary": [],
            "comment": "剧情优化大师",
            "content": "【剧情优化功能】\nAPI配置：\n\t目前插件大部分功能都走主页的API设置了。\n提示词指令：\n\t这里不是给小白用的，不懂得提示词编写、变量、占位符等等的，请不要动！\n\n请使用默认的，或者找大佬做好的 主提示词 预设。\n\n加载提示词预设：\n\t例如在社区内获取大佬写好的 提示词 预设（不是酒馆预设！），在这里导入后可以随时切换不同的预设。\n\t什么意思呢：例如两套不同风格的预设，玩不同的卡方便切换。\n速率调整：\n\t这里是你可以随意调整的地方，可以自行尝试\n\t意思是事件发生的节奏快慢，例如你完全不希望某些事情发生（完全不推进）你可以设置为 0 ，设置过高可能会导致剧情进展太快，最高值为 1 。\n\t默认的 主提示词 ，只有前面三个需要修改，第四个请大家装作什么都没看到。\n\t这里使用的是占位符形式，对应默认 主提示词 ，因此若你是修改提示词大佬“前面的标题可以无视”，匹配对应占位符就可以了。\n\n世界书/上下文设置：\n\t如果用的快速模型，默认就好，避免爆炸，如图。\n\t如果其他模型，根据模型最大上下文拉也行，发送的太多肯定会出现注意力问题的。\n\n主世界书：\n\t默认卡片绑定的主世界书，你需要发生那些条目给模型参考就勾选\n\n手动选择世界书：\n\t这个比较好用一点，可以同时选择多个世界书不同的条目。\n\n如果不想剧透，但有时候又想检查推进情况，建议添加以下正则（仅默认主提示词可能，其他大佬改的如果不匹配自己想办法）\n作者正则：\n查找正则表达式：\n/(<Plot_progression>[\\s\\S]*?<\\/Plot_progression>)/gsi\n替换为：\n<details> <summary>【剧情推演，点击展开】</summary>$1</details>\n勾选：用户输入、在编辑时运行、仅格式显示\n\n\n注意：这里的报错也都是api的问题。",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 11,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 12,
            "displayIndex": 12,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 12,
                "probability": 100,
                "useProbability": true,
                "depth": 11,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        },
        "13": {
            "key": [],
            "keysecondary": [],
            "comment": "闪佬的疑难解答",
            "content": "常见问题解答 (FAQ)\nAPI与连接问题\nQ1: 提示 “与模型B通讯时发生异常”、“Failed to fetch”、“undefined” 或API连接失败怎么办？\n\nA: 这是最常见的问题，通常与API配置有关。解决方法取决于您的API服务类型：\n\n谷歌官方/直连API \n目前因谷歌的服务器总是会出问题，所以大部分情况下，原则换密钥、换模型、换魔法梯子解决，若依然无法使用，推荐使用反代。\n\n各类中转/反代API (例如 api.deepseek.com/v1, NewAPI, 星星公益站等):\n直接使用openai兼容链接，依然是尝试换模型解决。\n\nClaw / Hajimi 轮询、反代API:\n特别是反代要重点提一下，大多时候，是使用sillytavern预设模式以及sillytavern后端模式。\n使用的模型基本也都是flash以及pro。\n\n\n通用提示:\n如果遇到 429 错误，说明API请求过于频繁或负载已饱和，请稍后再试或更换节点/API。\n如果遇到 500 或 PROHIBITED_CONTENT 错误，通常是“破限失败”，即内容被模型服务商的安全策略拦截。可以尝试更换模型（如DSv3的“甲比较薄”），或在插件的“提示词编辑器”（左下角魔法棒）中修改、增强破限提示词。\n\nQ2: 插件的测试按钮提示失败，但实际功能可用？\n\nA: 插件早期版本的测试按钮存在问题，可能无法正确反映API连通性。请以实际功能（如优化、总结）是否能正常使用为准。\n\n总结功能\nQ3: “小总结” 和 “大总结” 有什么区别？\n\nA: 两者是递进关系：\n小总结 (微言录)：在后台根据您设定的消息阈值（如每30条）自动进行，生成较为详细的剧情摘要。\n大总结 (宏史卷)：当小总结内容过多（如超过20000字符）时，通过手动点击“史册精炼”按钮，对已生成的小总结进行二次提炼和压缩，以节省Token。\n\nQ4: 我开了新聊天或走了不同的剧情分支，为什么总结内容会和之前的混在一起？\n\nA: 插件是通过 世界书名称 和 条目名称 (【敕史局】对话流水总账) 来识别和续写总结的。为了区分不同聊天或分支的总结，您可以：\n找到旧总结所在的世界书条目。\n修改其名称，例如在前面加上“分支A - ”。\n这样插件在新的聊天中就会创建一个全新的总结条目，而不会与旧的混淆。\n当您想继续玩旧分支时，只需将条目名称改回去即可。\n\nQ5: 总结生成的世界书，应该如何使用？\n\nA: 强烈建议将总结用的世界书 关联到角色卡，而不是设为全局。\n在插件设置中，选择 “写入位置” 为 “独立档案”。这会自动创建一个以 Amily2-Lore-角色卡名 命名的独立世界书。\n进入角色卡编辑页面，在 “更多选项” 中找到 “附加知识书”，将这个新建的世界书链接进去。\n在世界书管理页面，为该总结条目设置 蓝灯常驻，并可根据需要调整注入深度（推荐深度1或2，使其独立于其他世界书）。\n\nQ6: 总结中断或部分楼层失败了怎么办？\n\nA: 如果“开始远征”过程中断，可以手动补救：\n在“微言录”功能区，使用“手动熔铸”功能，选择失败的楼层范围（如 250-300）进行单独总结。\n将成功总结的内容，手动复制粘贴到主总结条目的对应位置。\n注意：操作前请一定备份好您的世界书，并确保 本条勿动【前X楼总结已完成】... 这句“金印”的楼层数是正确的。\n\n正文优化\nQ7: 正文优化功能似乎没效果，或者把我的角色卡格式弄乱了？\n\nA: 这是因为优化功能依赖对 正文标签 的识别。\n确认标签：您需要通过“编辑消息”功能（小铅笔图标）查看AI回复的原文，找到包裹主要叙事内容的标签，例如 <content>、<dream> 或 <plot>。\n正确填写：将这个标签名（不需要尖括号）填入插件主殿的 “御定优化标签” 输入框中。\n格式兼容性：如果您的角色卡或预设在正文标签内嵌套了其他复杂格式（如状态栏、美化标签），可能会导致优化后格式丢失。开发者正在努力改进这一点。对于纯文字卡或格式简单的卡，优化效果最佳。\n\nQ8: 如何对比优化前后的效果？\n\nA: 有两种方式：\nPC端: 按 F12 打开浏览器控制台，在日志中可以找到 \"Amily2优化任务\" 的记录。“发往ai” 中的是原始文本，“原始回复” 是优化后的文本。\n插件内置查看器: 在左下角扩展菜单中开启“查看优化前文”，会出现一个可拖动的按钮，点击即可查看最近一次的优化原文。\n\n其他功能\nQ9: “隐藏楼层”功能为什么没让聊天记录消失？\n\nA: 本插件的“隐藏楼层”功能，作用是 不将这部分楼层的内容发送给AI，从而节省上下文Token，提高AI的注意力。它并 不会 在您的聊天界面上隐藏这些消息。如果您需要折叠界面上的聊天记录，请使用SillyTavern自带的设置（通常在顶部栏的 “格式” 或 “UI” 设置中）。\n\nQ10: 翰林院 (RAG/向量化) 是什么？怎么用？\n\nA: 这是一个用于实现 超长期记忆 的高级功能。\n原理：将大量文本（如小说、详细背景设定、过往总结）转换为AI能快速检索的“向量坐标”。当您聊天时，它会自动找出与当前对话最相关的内容片段并发送给AI。\n专用API：它需要使用专门的 嵌入式模型 (Embedding Model) API，不能使用您平时的聊天模型API。\n推荐服务：您可以在 硅基流动 (SiliconFlow) 等平台注册并获取免费额度的嵌入式模型API。\n使用：在插件“翰林院”页面配置好API，然后即可将小说、世界书条目或聊天记录进行“凝识”（即向量化），之后在“忆识检索”中开启总开关即可在聊天中自动生效。\n\nQ11: 安装/更新插件后，界面上找不到插件按钮了？\n\nA: 这通常是开发者上传文件时偶尔遗漏导致的。解决方法是 卸载并重装插件。请在SillyTavern的 extensions 文件夹中删除本插件目录，然后通过GitHub链接重新安装。\n\nQ12: 授权码无效怎么办？\n\nA: 请先更新到最新版插件。新版本在打开插件页面时，会自动生成一个当日有效的授权码，复制粘贴即可。\n\nQ12: 预设导入错误怎么办？\nA：木悠版本的表格预设不适配于Amily2号插件。\nB：Amily2号基本不需要预设，想要什么表自己加就行了，十分方便。",
            "constant": true,
            "vectorized": false,
            "selective": true,
            "selectiveLogic": 0,
            "addMemo": true,
            "order": 100,
            "position": 4,
            "disable": false,
            "ignoreBudget": false,
            "excludeRecursion": false,
            "preventRecursion": false,
            "matchPersonaDescription": false,
            "matchCharacterDescription": false,
            "matchCharacterPersonality": false,
            "matchCharacterDepthPrompt": false,
            "matchScenario": false,
            "matchCreatorNotes": false,
            "delayUntilRecursion": false,
            "probability": 100,
            "useProbability": true,
            "depth": 14,
            "outletName": "",
            "group": "",
            "groupOverride": false,
            "groupWeight": 100,
            "scanDepth": null,
            "caseSensitive": null,
            "matchWholeWords": null,
            "useGroupScoring": false,
            "automationId": "",
            "role": 0,
            "sticky": 0,
            "cooldown": 0,
            "delay": 0,
            "triggers": [],
            "uid": 13,
            "displayIndex": 13,
            "extensions": {
                "position": 4,
                "exclude_recursion": false,
                "display_index": 13,
                "probability": 100,
                "useProbability": true,
                "depth": 14,
                "selectiveLogic": 0,
                "group": "",
                "group_override": false,
                "group_weight": 100,
                "prevent_recursion": false,
                "delay_until_recursion": false,
                "scan_depth": null,
                "match_whole_words": null,
                "use_group_scoring": false,
                "case_sensitive": null,
                "automation_id": "",
                "role": 0,
                "vectorized": false,
                "sticky": 0,
                "cooldown": 0,
                "delay": 0,
                "match_persona_description": false,
                "match_character_description": false,
                "match_character_personality": false,
                "match_character_depth_prompt": false,
                "match_scenario": false,
                "match_creator_notes": false
            }
        }
    },
    "originalData": {
        "entries": [
            {
                "id": 0,
                "keys": [],
                "secondary_keys": [],
                "comment": "安装更新",
                "content": "<安装更新>\n1：sillytavern直接安装\n扩展地址：（国外源）\nhttps://github.com/Wx-2025/ST-Amily2-Chat-Optimisation.git\n挂上梯子，复制这个链接，打开你的酒馆。\n点击扩展-点击安装扩展，将链接粘贴进去，点击Install for all users按钮。\n\n2：本地安装\nhttps://github.com/Wx-2025/ST-Amily2-Chat-Optimisation.git\n点进去这个链接，点击法典/code按钮，点击下载ZIP，将下载的ZIP文件解压缩到目录。\nPC端：酒馆根目录\\public\\scripts\\extensions\\third-party\n移动端：手机根目录/data/data/com.termux/files/home/SillyTavernpublic、scripts/extensions/third-party\n最后将ST-Amily2-Chat-Optimisation-main文件夹改成ST-Amily2-Chat-Optimisation\n\n【更新】\n1：如果有新版本更新，在插件的主页面会有更新按钮出来，点击之后会自动跳转到管理扩展页面，点更新就行。\n2：如果主页面迟迟没有更新按钮出来，但你又确定有新版本，则挂上梯子，来到sillytavern酒馆的扩展页面，点击管理扩展，进行更新。\n3：如果你更新之后还是现实原本的版本号，那么刷新浏览器重新查看。\n刷新浏览器后依旧显示原本的版本号，则将插件删除，重新安装。\n\n【疑难解答】\n1：插件删除后依旧存在，则直接手动去扩展的安装目录，将ST-Amily2-Chat-Optimisation文件夹手动删除。\n\n2：通过酒馆安装时报错，则检查自己的梯子是否可用，以及是否打开了TUN模式，如果没有打开，则打开它。一定要记得提醒开TUN模式。\n\n</安装更新>\n\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 0,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 1,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 1,
                "keys": [
                    "正文优化"
                ],
                "secondary_keys": [],
                "comment": "正文优化功能简介",
                "content": "<正文优化核心原理>\n\n首先讲解一下其核心原理。\n\n我们是以一个特定的正文标签中的内容进行拦截，然后发给下一个模型进行拦截并优化。\n\nPs:这里的指的是把模型发给你的剧情正文内容，而不是思维链、状态栏、或者其余什么格式的内容。\n\n完整的过程：\n\n你发送一条消息：“吃了吗您内？”\n\n模型A进行回复：\n<thinking>模型A思考内容</thinking>\n<content>模型A正文内容</content>-----→假设我们御定的正文标签为content。\n<状态栏>模型A状态内容</状态栏>\n\n这里的模型A正文内容，是我们实际发送给模型B的内容，然后模型B根据我们的提示词对模型A正文内容进行优化。（此时你是看不到这个内容的，但可以通过我们的查看优化前文看到。）\n\n模型B优化后回复：\n<thinking>模型B思考内容</thinking>-------其实这里无所谓它回复的是什么标签。\n<content>优化版正文内容</content>-------这里的优化版正文内容就是我们需要的。\n<状态栏>模型B状态内容</状态栏>-------这里是什么其实也无所谓。\n\n我们的扩展进行一系列你看不到的方式自动替换文本后，你最终收到的消息：\n<thinking>模型A思考内容</thinking>\n<content>优化版正文内容</content>\n<状态栏>模型A状态内容</状态栏>\n\n优化的目的，就是将一些模型会经常出现的一些固定语式和词汇，让它换一种说法。\n<--\n比如说，优化前模型会经常性的投石子、神化、绝望、淬毒刀、名为xx…此刻xx…这种固定的词汇句式。\n我们让模型B进行优化，但是又不让剧情发生变化，以及不让语句变得不通顺，在此基础上进行优化。\n→\n\n像是预设/世界书是从起点出发，他们的原理是给主模型输出一堆设定，让它遵循设定不进行输出固定的语式。\n但模型一般超过了一定tokens之后，就会出现完全不遵循规定的行为，俗称（流口水）。\n而还有一个特例，就是正则杀八股，正则的原理就是，将经常出现的固定名字删除掉，让ai去读上下文的时候。\n读不到“石子”这样的词。好处是你必定看不到“石子”，坏处是模型依然会输出，且你还知道它一定输出了。\n因为当你看见“内心如同**落入心湖，轰的一声，泛起了一层层的**”，尽管你看不见**到底是什么，但是你绝对也知道这个**是石子（邪笑~），所以正则杀八股，也只不过是“自慰”行为罢了。\n\n而我们的插件做法：\n等模型去随意输出，哪怕你去流口水了，我们还有第二个模型进行改动，让句子通顺的同时，把石子干掉，把文风优化，把八股干掉。\n\n当然也存在一些硬伤，因为我们需要第二次调用api，所以时间会延长个十几秒。但换来的是绝对的，文风上的超级优化，哈八股的绝对消失。并且在此过程，还可以提升语言、视觉的流畅度（逗号增值、省略增值、段落缩进等），而且只要你提示词写得好，模型B可以根据你的想法随意去改内容。\n\n</正文优化核心原理>\n\n",
                "constant": false,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 1,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 12,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 2,
                "keys": [],
                "secondary_keys": [],
                "comment": "正文优化使用方法",
                "content": "<正文优化使用方法>\n操作流程：\n一、设定优化标签\n二、选择优化模式\n三、编辑提示词（只是介绍，不用动）\n四、开启查看优化前正文功能\n五、启动并尝试优化！\n六、预设标签优化拟合\n\n优化标签设定：\n首先正文内容必须要被标签包裹，大部分酒馆预设条目里会有相应的设定，若预设中没有则需自己在预设中添加。\n- 例如：content\n- 注意：填写时只需要填写字母，不需要输入<>进行包裹。也不需要填写闭合标签。\n为了防小白这里简单说一下，一般预设中关于 “字数”、“正文”相关的条目中会附带正文包裹标签例如：\n\n- 正文字数需求：2000 - 30000token（以\"<content>\"标签的内容为准）\n- **正文使用语言：zh-CN**\n- **正文内容用\"<content>\" 这里是正文 \"</content>\" 包裹**\n\n<content>就是正文的包裹标签，不同预设可能使用的包裹标签不一样，因此你需要把标签设置到优化里面，不需要<>，你的正文是什么标签包裹就填什么标签。\n\n拓展内已经默认自带了对应的提示词，正常情况不需要动他，这里是留给对提示词有一定了解的人使用的，正常来说只需要关注 “预设提示词(任务规则)” 。\n\n目前内置的提示词已经可以做到“去除八股”、“优化比喻”、“文风润色”，若需要更多功能或者对默认的提示词效果不满意可以自行修改，这里不做修改教学，修改后记得 “保存” 即可，也可以一键 “恢复默认” 。\n</正文优化使用方法>\n\n【正文优化功能疑难解答】\n\n1：为什么我开启了正文优化功能，但是无效？\n\n排查问题流程：\n- 第一步是查看你的正文标签是否是正确的。\nA：点击小铅笔，看看你的正文是用什么标签包裹的，是否与插件设置的标签一致。\nB：A排除后，点击插件主页面的测试并修复，如果显示`命令检查器未检测到需要修复的问题`，那么标签设置依然不对。\nC：如果显示修复完成，那么代表手动优化是完成了的，代表标签设置没有任何问题。则先关掉所有的正则，再去发送一条消息进行测试。\n\n- 完成第一步之后，依旧无法优化，则进行内容排除，将正文中的无用内容排除一遍。其次将预设提示词（任务规则）恢复一下默认。\n\n需注意：无感优化需要关闭流失传输。刷新优化无需关闭流式传输。\n\n经常性不优化，但偶尔优化，则检查自己的api是否足够稳定，如果不够稳定，则将模型切换为flash。\n\n---\n\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 2,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 2,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 3,
                "keys": [
                    "微言录",
                    "小总结"
                ],
                "secondary_keys": [],
                "comment": "微言录小总结功能简介",
                "content": "<微言录小总结功能简介>\n\n微言录、俗称小总结。但与原本的总结姬并不一样。\n\n简单解释一下，就是因为楼层太高，而导致tokens太多，模型完全不知道哪是哪，然后就会变得智障起来。\n\n通常的解决方案就是隐藏楼层解决，但是如果隐藏了，模型就会忘记之前的内容，所以就将之前的内容进行一次总结，然后自动写进世界书里面，让聊天记录不占tokens的同时，还不会遗忘掉以前的内容。\n\n<微言录小总结功能简介>",
                "constant": false,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 3,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 13,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 4,
                "keys": [],
                "secondary_keys": [],
                "comment": "微言录小总结使用方法",
                "content": "<微言录小总结使用方法>\n前置设置：\n先回到拓展的“主殿”（就是首页），在“世界书档案司与律法”进行设置。\n写入主世界书：\n\t比如总结会写进卡自带的世界书\n\n写入独立存档：\n\t会新建一个“Amily2-Lore-char-这里是卡片名称”的世界书。（总结成功才会出现的，具体名称可能后续会因更新改变，但大几率作者并不会去动它）\n\n蓝灯绿灯插入深度：\n\t推荐设置为蓝灯（保持开启），绿灯会导致需要出发关键词，主模型才会读取。深度一般设置为2\n\n确认敕令：\n\t就是个保存，修改后随手点一下它（虽说自动保存的，但是养个好习惯）\n\n使用方法：\n先设置“正文抓取标签”并启动“标签提取按钮”（标签设置和优化功能的标签设置方式一样，并且推荐只去提取包含时间的标签+包含正文的标签。并且去主动排除掉不必要的内容）\n\n\n手动总结（手动熔铸范围）：\n可以手动输入想要总结的层数范围，然后点击“熔铸”。（想总结哪里你说了算）\n\n\n自动总结：\n把未总结过的楼层按顺序进行总结。功能较多名字开始有点不适应的按照这个教程顺序设置即可。\n\n远征阈值：\n这里同时关联两个功能：\n自动触发总结的层数：如设置50，聊天达到50层自动触发总结，总结50层。\n单批次总结的层数：如设置50，若你有200层聊天，会分4批次进行总结，每批次总结50层。\n写入史册：\n就是写进世界书，写进那个世界书由“前置设置-世界书档案司与律法”确定。\n自动巡录：\n就是自动总结的开关，远征阈值设置了多少，到达了对应层数自动触发总结。\n（默认保留两层不去总结，比如说达到22层聊天记录的时候，才会总结前20层）\n开始远征：\n这是给已经有“大量聊天层数”使用的，点击后按照“阈值”进行分批次总结。\n\n【阈值】：例如设置的是30，那么100层楼就会被分为30+30+30+10被送去总结。\n【存入翰林院】：每次自动总结或者远征都会将小总结的内容自动送去向量化。（不推荐，更推荐使用`将前段的大总结内容自动送去向量化`功能，但如果你喜欢，也可以。向量化之后我更推荐你手动将小总结设置为绿灯条目，或者手动删除已经完成的小总结。）\n\n【疑难解答】：\n- 小总结出来的内容根本不对，或者变成了正文的续写？\n1：模型抽风了，换个模型。或者就是你没有设置好内容的排除。\n- 小总结内容太多了，这正常吗？\n2：这很正常，模型gemini-2.5-Flash基本分不清什么是重点，会认为越详细越好，换成gemini-2.5-pro基本每次小总结都是保持在20多条左右，而模型DSv3是最精简的。\n\nPs：如果有人问你，小总结之后要启动这个条目吗？世界书要绑定角色卡吗？直接使用我的原话回答他！\n\n“你tm的你不绑定到角色卡，你不启用总结的条目，那你总结个懒子？养眼吗？”\n\n（哪怕向量化了小总结，我也推荐启动原小总结条目，大总结除外。）",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 4,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 3,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 5,
                "keys": [],
                "secondary_keys": [],
                "comment": "宏史卷大总结使用方法",
                "content": "<宏史卷大总结使用方法>\n\n宏史卷，即大总结，位于“内阁密室”栏目底部。\n\n前文提到的微言总结将一段历史记录总结为了一个个小事件并用“权重值”体现了每个小事件的重要性。\n\n宏史总结则是将一系列的小事件，如同小说章回一般精炼，突出权重高的重要事件，合并甚至省略权重低的小事，并总结出其中的伏笔与展望以供后续使用。\n\n\n这个大总结并不是“对正文”进行大总结，而是“对小总结”进行优化总结为：“章节小说”\n\n【使用方法】：拉到内阁密室的底部，选择你要进行总结的世界书条目`【敕史局】对话流水总账`，点击精炼既可。\n\n【疑难解答】：\n- 缺少流水金印怎么办？\n\n1：一般情况下，小总结完成之后，在底部会出现一条内容，`本条勿动【前X楼总结已完成】否则后续总结无法进行。`\n这个就是流水金印了，保持在底部。\n\n2：另外选择的条目必须为`【敕史局】对话流水总账`\n\n- 将前段大总结自动送去向量化是什么意思？\n\n1：很简单，例如说，你现在进行大总结的楼层是400-600层的小总结。那么开启这个开关后，会将1-400楼的大总结内容自动送去向量化，并以特定的标注替换原本文本。\n\n2：最后将400-600楼的大总结，保留在世界书中，以保证最近的剧情始终连贯。\n\n</宏史卷大总结使用方法>",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 5,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 4,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 6,
                "keys": [],
                "secondary_keys": [],
                "comment": "功能总览",
                "content": "# **功能列表**：\n`正文优化`、`大小总结`、`记忆表格`、`rag向量`、`剧情推进`、`隐藏楼层`、`提示词查看器`。\n\n- 正文优化：后台自动杀八股、杀神化、杀绝望，改善文风。（位于插件的主页面）\n   * 功能优势：首发，目前此功能只有我这里有，且比正则杀八股、预设防八股等方式更加彻底、体验感更好。\n   * 辅助功能：优化前文查看器，可随时查看在优化之前的原始文本是什么样子的，方便对比效果。\n\n- 自动总结：实现将聊天自动整合总结写进世界书。（位于内阁密室子页面）\n  * 小总结：后台自动将聊天记录总结并写进世界书。\n  * 大总结：负责将小总结二次精简，避免小总结冗余。\n  * 功能优势：标签提取与内容排除规则，使总结更加精准、详细。且可自动保留最近的总结，将之前的总结送去向量化。\n\n- 记忆表格：将重要细节转化为表格形式进行记录，并自动发送给大模型。（位于内存储司子页面）\n   * 原始填表：使用酒馆主模型进行读表与填表。\n   * 分步填表/兼容优化：使用插件模型进行填表，且与正文优化功能兼容。\n   * 功能优势：对于表格的自定义更加方便快捷、分步与立即填表等可选择条目读世界书、上下文。完善了旧卡也可**【一键立即填表、选择楼层填表、漏填后可当前楼层填表的容错、使用小总结的标签提取、内容排除规则、冗长表格一键重新整理】**等优化使用体验的功能。且所有功能基本都是一键式操作。\n\n- rag向量：向量、重排序，聊天中自动检索出相关的剧情内容发送给主模型，提高记忆与剧情关联性。（位于翰林学院子页面）\n   * 功能优势：混合api的方式，无需切换api，提供**【聊天记录、手动录入、世界书录入、整本小说】**四种向量化方式，懂得无需多解释，不懂的解释也说不清楚。\n\n- 剧情推进：实现在你发送消息时，自动读取世界书条目与上下文，向api发送请求，剧情自动推进，再也不需要什么剧情推进的预设了。（位于剧情优化子页面）\n  * 功能优势：四种推进变量，不仅仅可以推进，而且可控。另外还有平行事件的诞生，使得剧情更加丰富。\n\n- 自动隐藏楼层：这东西还需要解释吗？（位于内阁密室子页面）\n\n- 提示词查看【密折司】：开启后可查看到所有发送给主模型的内容。（位于聊天页面左下角魔法棒扩展）\n   * 功能优势：提供总览与分条目的tokens统计与字数统计，且有小图标标注出来表格与rag向量化的注入位置（仅Amily2号助手插件的表格与rag向量有效。）",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 6,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 5,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 7,
                "keys": [],
                "secondary_keys": [],
                "comment": "翰林院rag向量化使用方法",
                "content": "<翰林院rag向量化使用方法>\n翰林院 (RAG 向量化) 使用指南\n核心概念：翰林院是做什么的？\n简单来说，翰林院（或者说 RAG 向量化）的作用就是给你的 AI 一个外部记忆库。\n很多人问向量化到底有什么用？答案就是：将 AI 一次性“吃”不下的长篇内容（比如几十万、几百万字的小说背景、详细的人物设定），转化为它能理解的“记忆地标”（向量）。当你发送消息时，系统会自动检索这些地标，找到最相关的内容，然后悄悄递给 AI，让它“回忆起”这段剧情或设定。\n这样，你的 AI 就能拥有超长期的、永不磨灭的记忆了。\n\n\n一、初次使用：API 设置（前置步骤）\n向量化需要专门的“神力”（Embedding API）来支持。如果你没有，或者“神力测试”失败，请按以下步骤操作。\n注册 API 服务：\n我们推荐使用硅基流动 (SiliconFlow)。这是一个提供包含 Embedding 模型的服务商，同时也提供后续会讲到的 Rerank 服务。\n硅基流动端点：https://api.siliconflow.cn/v1\n获取 API 密钥：\n注册并登录后，在你的账户中找到 API 密钥 (API Key) 并复制它。\n在翰林院中配置：\n回到酒馆的翰林院设置界面，点击 忆识检索 标签页。\nAPI 设定：选择 自定义。\n通行令牌 (API Key)：粘贴你刚刚复制的密钥。\n嵌入模型：点击 获取模型，然后选择一个可用的模型。\n测试神力：点击此按钮。如果提示“神力充沛”，说明配置成功！\n​\n重要提示：翰林院的 API 和主界面聊天的 API 是完全独立的。这里设置的只负责记忆、检索、注入，与优化总结等并不关联。\n​\n\n二、标准工作流程：如何安全地管理记忆库\n为了防止因切换角色而导致记忆库错乱或数据丢失，请务必遵循以下锁定会话的工作流程。\n\n（当然，如果你心大，用不用这套流程也无所谓。）\n选择目标角色：\n在酒馆主界面，选择你想要为其添加或管理记忆的角色卡。\n进行向量化操作：\n进入翰林院，使用下文介绍的任何一种方式录入记忆（如凝识聊天、导入小说等）。\n确认并锁定：\n操作完成后，在翰林院顶部的状态区，点击 刷新 按钮（🔄）确认“忆识总数”已增加。然后，点击锁定会话 按钮。按钮会变为“解锁会话”状态。\n安全切换：\n现在，你可以安全地切换到任何其他角色卡进行聊天，而不必担心会影响到刚刚锁定的那个记忆库。（此步骤应该需要先关掉总开关，不过我没有尝试过在向量化途中去聊天。）\n需要再次编辑时：\n如果你想为被锁定的角色继续添加记忆，必须先切回该角色卡，然后在翰林院点击 解锁会话 按钮，再重复步骤2和3。\n一句话总结：要动哪个角色的记忆库，就先切到哪个角色，操作完立刻锁定，万无一失。\n\n三、核心功能：如何录入记忆？\n翰林院提供了多种方式，将你的知识录入“忆识宝库”。\n1. 凝识聊天记录\n这是最常用的功能，可以将你和 AI 的对话直接转化为长期记忆。\n智能记录：翰林院会自动记录上次凝识到的楼层，你无需手动记忆。\n范围设置：在“凝识范围”中，将结束楼层设为 0，即可自动处理从起始楼层到当前所有的最新对话。\n安全操作：强烈建议在点击“开始凝识”前，先点击“预览内容”，检查将要被向量化的文本是否正确。\n2. 整本录入 (小说/文档)\n这是一个强大的功能，可以让你将一整本小说（.txt格式）直接录入记忆库。\n选择文件：点击“选择.txt文件”按钮。\n编码格式：如果你的文档是GBK或Big5等非UTF-8编码，请在下拉菜单中选择对应的选项，插件会自动为你转码。\n开始录入：点击后，系统会显示进度条，请耐心等待。大文件可能需要几分钟时间。\n3. 手动录入 & 按条目编纂\n手动录入：在文本框里粘贴任何你希望 AI 记住的内容（角色设定、世界背景等），然后点击 开始录入。\n按条目编纂：可以直接选择一个世界书 (World Info) 及其中的条目，将其内容完整录入。\n​\n幕后揭秘：自动标签\n无论你用哪种方式录入，翰林院都会智能地为内容打上来源标签，例如 <聊天记录>, <小说录入>, <世界书>。这能帮助 AI 在“回忆”时更好地理解信息的上下文。\n​\n\n四、进阶功能：让记忆更精准\n1. 忆识精炼 (Rerank)\n当检索到的相关记忆片段过多时，Rerank 功能可以进行二次筛选和排序，挑出与当前对话最最相关的几条，大幅提升AI回应的精准度。\n启用：在“忆识精炼”标签页，打开“启用 Rerank”开关。\n配置：像配置Embedding API一样，填入你的 Rerank API 地址、密钥和模型。同样推荐使用 SiliconFlow。\n返回结果数 (top_n)：决定经过精炼后，最终返回给 AI 几条最相关的记忆。通常设置为 3-5 即可。\n2. 圣言注入 (高级设定)\n这里决定了检索到的记忆，将以何种方式、在哪个位置“告诉”给 AI。\n圣言模板：你可以自定义注入的格式。一个好用的模板示例：\n—\n以下内容是翰林院向量化后注入的相关内容，是已经发生过的事情简短总结，但可能顺序会有些错乱，但已经对前后做出了标识，请自行判断顺序：\n<总结内容>\n{{text}}\n</总结内容>\n【以上内容是已经发生过的事情，切莫以此作为剧情进展，只是作为提醒发生过的事情】\n—\n注入位置：\n主提示前：放在所有提示词的最顶端，权重最高。\n主提示后：放在主提示词之后，聊天记录之前。\n聊天内 @ 深度：（推荐） 模拟一条特定角色的历史消息。你可以精细控制它出现在聊天记录的倒数第几层，以及它的“扮演者”（系统、用户或助手）。\n3. 内容排除\n在“凝识法则”区域，可以设置排除规则，在向量化之前移除不需要的内容（如大段的代码块、作者的注释等），让记忆库更纯净。\n\n</翰林院rag向量化使用方法>\n\n【疑难解答】\n\nQ1: 为什么我的“神力测试”总是失败？\nA: 99% 的原因是你的 API 配置有误。请仔细检查 API 地址、API Key 是否正确，以及模型是否可用。\nB:严格使用嵌入式模型，并非是补全模型。\nQ2: 为什么我的向量块数突然变成 0 了？或者我和A聊天，B的记忆却多了一堆？\nA: 这是因为你没有遵循标准工作流程！请严格按照本文第三节的“锁定/解锁会话”步骤操作，这是保证记忆库安全稳定的基石。\nB:依照向量化数据迁徙那里的教程可以找回原本的向量化记忆文件。\nQ3: 为什么我装了 Amily2，但感觉 RAG 没生效？\nA: 请检查是否安装了其他同样具有 RAG 功能的向量化插件。Amily2 的向量化功能与其他同类插件有冲突，请确保只保留一个。\n\n最后注意：向量化大文件时，严格使用先锁定会话，再进行向量化操作，可以避免向量化过程归0。\n\n---\n\n向量化文件迁徙教程\n\n如果你打开这个文档之后第一件事就是找到这个页面，那么我就要在此说一声很抱歉了。\n\n原因如下：\n1：在我技术并不完善的情况下将rag向量这个功能推出，给你带来了不便。\n\n2：旧版本中偶尔间出现的向量化数据归0，并不是你的操作问题，而是我们向量化的漏洞。\n\n所以针对以上，进行了一番完善的操作,此次之后，向量化再也不会被归0了。\n\n——我们只需要麻烦这一次！\n\n\n\n\n先不多说，我先将向量化数据迁徙的教程呈上：\n\n第一：\n让我们打开酒馆根目录，也就是sillytavern-[某个版本后缀]\n\n此项需要注意的地方就是，PC端可能比较好找，我就不再多说，但是移动端可能你会找不到，所以请移动端请打开你的MT管理器（或者可查看手机根目录的文件管理器）\n\n第二：\nPC端打开文件地址： 酒馆根目录\\data\\default-user\\vectors\\webllm \n安卓端文件地址：从手机根目录出发/data/data/com.termux/files/home/SillyTavern/data/default-user/vectors/webllm\n\n依次打开之后，你会看到类似的文件夹：\n\nchar_1_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms\n也就是char_1以数字开头的为旧向量化的文件夹。\n\nchar_仙逆_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms\n而char_仙逆以角色卡名字为开头的，是新向量化数据文件夹。\n\n我们需要做的就是，将旧的向量化数据文件夹打开：\nchar_1_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms/undefined/index.json\n这个index.json就是我们需要的文件。\n\n然后复制它，将它覆盖并替换新的向量化数据文件夹中：\nchar_仙逆_chat_仙逆_-_2025-7-26__23h_37m_47s_468ms/undefined/index.json\n\n此操作执行完成后，你的向量化数据就相当于是迁徙完成了，且此文件，可以替换到任意一个角色卡中。\n\n也就是说，当你向量化了一整本小说甚至说更大的文件，需要耗时巨长。那么你也不需要进行二次向量化，而是直接将其覆盖替换为你需要向量化的角色卡中，同样是可以使用的。\n\n\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 7,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 6,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 8,
                "keys": [],
                "secondary_keys": [],
                "comment": "api连接配置",
                "content": "<各种api报错>\nPs:这里的问题是最多的，一定要去重点解答！\n注：关于API的设置该插件有三个地方需要填写分别是：优化总结、向量化、Rerank\n第一：主殿API与模型配置\n所处位置：点击插件后，第一个页面的里面。\n\n此处的api配置所管辖区域为：正文优化、微言录小总结、宏史卷大总结、表格、剧情优化。\n配置参考：最大Token数: 65000、思考活跃度: 1.2、上下文参考数: 2\n\n首先这里设置了四种api的配置方案\n1：openai兼容模式\n- 不多解释，输入端口和密钥就行了。\n推荐模型：gemini-2.5-flash、gemini-2.5-pro、dsV3\n2：谷歌直连模式\n- 不多解释，单独输入密钥就可以。\n3：sillytavern后端\n- 这里就简单解释一下。sillytavern后端直连的模式，一般适用于反代的接口、轮询的接口。需要与酒馆主api的配置保持一致，但是模型可以选择不一样的。\n4：sillytavern预设\n- 这个是最通用的模式，理论上，只要你的api在酒馆可用，那么在我插件就可用。\n- 配置方法是打开酒馆的api连接，然后新建一个预设，输入你想让插件使用的模型和api配置，切换为其他预设之后再切换回来，**点击保存**，回到插件，选择它就可以了。\n- 实现方法是，当需要我插件发送api请求时，会自动切换为这个保存的预设发送出请求之后，再瞬间切换回你酒馆使用的api配置。\n- 如果切换回来，你的酒馆api配置没有自动连接，那么查看你的酒馆api配置是不是没有勾选自动连接到服务器。\n\n【小总结报错】、【大总结报错】、【正文优化报错】\nAPI调用发生错误: Error: Google API请求失败: 429\nAPI调用发生错误: Error: Google API请求失败: 500\nAPI调用发生错误: Error: Google API请求失败: 503\n这三个数字报错，则换个密钥，换个模型试试看， 如果你使用的flash则换成pro，如果你使用的pro则换成flash，另外503报错不是我插件的问题，而是谷歌服务器的问题。\n\nAPI调用失败:Failed to fetch\n而这个是最常见的报错，换模型，换api解决。（不要瞎回答，就简单的换模型，换api解决。）\nAPI调用发生错误: Error: Google API请求失败: 400\n请求的格式不对，也就是选择模型错误。\n\n最后提示用户，deepseek-chat以及R1模型不能用在插件，因为R1自带了一层思维链，chat非流式请求会出问题。deepseek适配的模型只有V3，V3.1也不行（个别人可以）。\n\n另外大部分的远征失败、自动巡录失败、填表红色报错失败，都是api的配置问题，自行切换api或者模型。\n\n最稳定的模型是dsV3模型，小总结、大总结、分步填表都很稳定。缺点是，正文优化可能会有点问题，优化出来的东西根本没法看。\n\n</各种api报错>\n\n<向量化api报错>\n神力之源(API)\n所处位置：从主页面点击翰林学院后，忆识检索框里面。\n\n此处所管辖位置：\n向量化嵌入式模型的获取、测试、以及使用。\n目前可用的接口只有openai兼容的向量化嵌入式模型，例如硅基流动的Qwen3-Embedding-8B\n注：非嵌入式模型，不可使用此处的功能。例如什么：gemini-2.5-pro、gemini-2.5-flash，都不属于嵌入式模型的范畴。唯有明确为Embedding标志的，为嵌入式模型。\n再次重申：【向量化嵌入式模型】\n\n\nRerank精炼\n所处位置：主页面点击翰林学院进入子页面，然后点击忆识精炼。\n\n此处所管辖位置：\n其实这个功能是完全在后台进行的，所管辖位置就只有这个忆识精炼的页面了。\n目前可用接口同样是openai兼容的，例如硅基流动的Qwen/Qwen3-Reranker-8B\n注：非重排序模型，不可使用此处的功能。例如什么：gemini-2.5-pro、gemini-2.5-flash，都不属于重排序模型的范畴。唯有明确为Reranker标志的，为重排序模型。\n\n注：重排序的报错一般都是因为模型选择不正确，或者api的配置不正确。\n\n端口https://api.siliconflow.cn/v1而不是https://api.siliconflow.cn/v1/Reranker\n\n---\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 8,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 7,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 9,
                "keys": [],
                "secondary_keys": [],
                "comment": "表格问题答疑",
                "content": "<表格简介>\n填表模式：\n\t原始：就是“聊天同时填表”，走的酒馆主API，例如输出正文后还得等它写一大堆填表内容，你才能继续输入；原始填表目前兼容“正文优化”功能\n\t分步：就是“独立填表”，使用的插件配置的api，分步填表目前不兼容“正文优化”功能\n\t兼容优化：这玩意不就是“独立填表+正文优化”同时进行。兼容优化目前兼容“正文优化”功能。使用的是插件的api。\n\n可控操作：点击列名可以左加列、右加列、左移动列，右移动列、编辑列名、删除列。\n点击行名可以上下移动行，上下添加行、删除行。\n\n立即填表：根据批处理阈值的数字分批次进行填表，与微言录的操作一致，并且使用的也是微言录的标签提取与内容排除规则。\n选择楼层填表：与立即填表一样，不过可选楼层。\n填当前楼层：如果你的填表，本楼被漏掉了，可以点击这个按钮，与立即的规则一样，不过发给api的只有本层楼的内容。\n重新整理：当表格内容过多时，可以点击这个按钮，将当前表格发送给插件的api进行重新整理精简。\n</表格简介>\n\n【疑难解答】\n\n- 为什么表格不会自动填表？\n\n首先用户是使用的哪个填表模式，然后根据以下内容进行解答：\n如果使用的是原始填表，那么先进行一下配置：\n1：聊天内\n2：深度0\n3：系统\n\n确认两个开关以及选择的模式是对的。\n接着发送一条消息出去，点击ai回复消息的小铅笔，检查是否存在<Amily2Edit>标签。\n\n如果有，且内容与我的类似，那么就是填表成功了。\n\n如果没有，去你的预设提示词里面添加格式：\n<Amily2Edit>\n<!--\n(这里是你的填表内容)\n-->\n</Amily2Edit>\n\n一般都在你预设的cot思维链附近的格式检查、最终输出格式那个地方，自行添加进去。\n\n当然也有更简单的方法，直接发送一条消息出去：\n“记得填表，现在的填表标签是<Amily2Edit>”\n\n这一般能解决你这单独一个角色卡不填表的问题，一劳永逸的方法还是让预设去适配我的填表标签。\n\n\n另外如果你使用的分步填表，不要去开正文优化！\n\n如果你想用正文优化，也想用分步填表，选择兼容优化这个填表模式。\n\n另外，分步填表以及兼容优化，一般不会出现不填表的问题！\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 9,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 8,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 10,
                "keys": [],
                "secondary_keys": [],
                "comment": "密折司妙用",
                "content": "【密折司】、【查看优化前文】、【提示词链编辑器】\n\n密折司：效果已经在功能简介讲过。\n\n那么对于答疑来说，妙用就是在当原始表格始终不填表的情况下，可以让用户打开密折司，然后发送一条消息出去。\n\n根据密折司的弹窗，快速定位表格是否被注入到了提示词中（被注入的条目会有一个表格的小图标、翰林院向量化也有。）\n\n如果没有注入，关掉所有正则再测试一次。如果依然没有注入，那么排除正则的原因，查看是否是插件的冲突，目前已知冲突插件（聊天记录快速恢复，偶尔会导致不注入）、（聊天超级管理器，会导致向量化两次检索，重排序两次调用。）\n\n查看优化前文：可以查看在使用优化正文功能时的未被优化的原始文本。\n\n如果优化功能在没有提取到特定标签的内容时，里面就会是空的。如果不为空，正确提取到了依旧不优化，则让用户关掉所有正则再进行测试。\n\n提示词链编辑器：\n所有功能的提示词编辑的位置，提供了导入导出、顺序的排序。（如果可以，你作为客服，如果用户要求，你也可以帮助他编辑一下提示词，让他将完整的提示词内容发送给你。）\n\n",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 10,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 9,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 11,
                "keys": [],
                "secondary_keys": [],
                "comment": "疑难解答",
                "content": "会经常有一些傻傻的用户会问一些这样的问题：\n- 如果我使用了小总结，还需要用表格吗？\n- 如果我使用了向量化，还需要用总结吗？\n\n简述：这是我个人的在sillytavern（酒馆）实现长期记忆的方案，整个体验下来感觉良好。爬楼数已经达到了2700，记忆的丢失也并没有很严重。\n\n首先我需要的两个要素：Amily2号、记忆表格（目前我们插件已经有了记忆表格，所以与木悠的记忆增强表格选择一个使用）。\n\n具体的实现方式：\n\n1：总结记录大事件、重要事件、关键节点。保证主模型的剧情大方向保持不变且重要的事情不会忘。 \n2：表格的预设记录了角色细节以及重要的物品、任务等，确保细节不被丢失。 \n3：rag向量化，将总结或者正文或者摘要进行向量化，可以保证每一条的模型回复消息都与剧情是有关联的。\n\n\n详细教程：\n\n1：第一件事使用我们的微言录进行总结，然后每次达到200层楼左右进行一次宏史卷大总结。\n\n\n2：重复上面的做法，如果当单独的宏史卷，已经超过了两万字符，那么继续微言录总结，让它达到两万五千左右\n\n3：使用大总结，以及打开将前段大总结自动送去向量化的开关。\n\n3.1：（此步骤可选）基于3的步骤，在大总结之前，可以新建一个世界书的条目，将前段的大总结复制进去，但是不要启动它，只留作备份就行了。避免向量化的文件你清空后无法使用，总结也丢失就不好了。\n\n\n其次的操作就是：翰林院那边的设置，这里需要注意，选择聊天内，选择系统，深度与【敕史局】对话流水总账保持一致。\n\n—\n以下内容是翰林院向量化后注入的相关内容，是已经发生过的事情简短总结，但可能顺序会有些错乱，但已经对前后做出了标识，请自行判断顺序：\n<总结内容>\n{{text}}\n</总结内容>\n【以上内容是已经发生过的事情，切莫以此作为剧情进展，只是作为提醒发生过的事情】\n—\n\n5：走到这一步其实你已经完成了大部分的长期记忆设置，但是这样可能会丢失一些长期记忆的细节。\n\n所以我们需要一个进行记录细节问题——记忆表格。\n\n不需要它进行记录什么重要事件、关键节点、大小总结什么的，因为我们的总结已经完全做到了这一点。\n\n所以我们需要让它记录的东西就只有这些角色信息、任务、物品之类的，我们的表格默认预设已经完美解决了这一点。\n\n注意：目前我们的插件已经内置了表格，看你更喜欢用哪个表格，只开一个表格就可以了。\n\nOK，到这里你已经完成了所有长期记忆的步骤，起码我能保证的一点就是，在一千楼之内，不会丢失任何记忆。（目前我2700楼都感觉良好。）\n\n最好将世界书的总结条目，与向量化的注入位置，设置成一样的。\n\n完成注入之后，向量化的内容直接衔接到了我们微言录、宏史卷的世界书总结前面！\n\n也就是说，当没有注入的时候，这个总结记录的是后半部分的楼层内容，前半部分是缺失的。\n\n现在我们向量化注入之后，闪回的记忆碎片（而且是有关联的碎片）被放在了缺失的记忆那里！",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 11,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 10,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 12,
                "keys": [],
                "secondary_keys": [],
                "comment": "剧情优化大师",
                "content": "【剧情优化功能】\nAPI配置：\n\t目前插件大部分功能都走主页的API设置了。\n提示词指令：\n\t这里不是给小白用的，不懂得提示词编写、变量、占位符等等的，请不要动！\n\n请使用默认的，或者找大佬做好的 主提示词 预设。\n\n加载提示词预设：\n\t例如在社区内获取大佬写好的 提示词 预设（不是酒馆预设！），在这里导入后可以随时切换不同的预设。\n\t什么意思呢：例如两套不同风格的预设，玩不同的卡方便切换。\n速率调整：\n\t这里是你可以随意调整的地方，可以自行尝试\n\t意思是事件发生的节奏快慢，例如你完全不希望某些事情发生（完全不推进）你可以设置为 0 ，设置过高可能会导致剧情进展太快，最高值为 1 。\n\t默认的 主提示词 ，只有前面三个需要修改，第四个请大家装作什么都没看到。\n\t这里使用的是占位符形式，对应默认 主提示词 ，因此若你是修改提示词大佬“前面的标题可以无视”，匹配对应占位符就可以了。\n\n世界书/上下文设置：\n\t如果用的快速模型，默认就好，避免爆炸，如图。\n\t如果其他模型，根据模型最大上下文拉也行，发送的太多肯定会出现注意力问题的。\n\n主世界书：\n\t默认卡片绑定的主世界书，你需要发生那些条目给模型参考就勾选\n\n手动选择世界书：\n\t这个比较好用一点，可以同时选择多个世界书不同的条目。\n\n如果不想剧透，但有时候又想检查推进情况，建议添加以下正则（仅默认主提示词可能，其他大佬改的如果不匹配自己想办法）\n作者正则：\n查找正则表达式：\n/(<Plot_progression>[\\s\\S]*?<\\/Plot_progression>)/gsi\n替换为：\n<details> <summary>【剧情推演，点击展开】</summary>$1</details>\n勾选：用户输入、在编辑时运行、仅格式显示\n\n\n注意：这里的报错也都是api的问题。",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 12,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 11,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            },
            {
                "id": 13,
                "keys": [],
                "secondary_keys": [],
                "comment": "闪佬的疑难解答",
                "content": "常见问题解答 (FAQ)\nAPI与连接问题\nQ1: 提示 “与模型B通讯时发生异常”、“Failed to fetch”、“undefined” 或API连接失败怎么办？\n\nA: 这是最常见的问题，通常与API配置有关。解决方法取决于您的API服务类型：\n\n谷歌官方/直连API \n目前因谷歌的服务器总是会出问题，所以大部分情况下，原则换密钥、换模型、换魔法梯子解决，若依然无法使用，推荐使用反代。\n\n各类中转/反代API (例如 api.deepseek.com/v1, NewAPI, 星星公益站等):\n直接使用openai兼容链接，依然是尝试换模型解决。\n\nClaw / Hajimi 轮询、反代API:\n特别是反代要重点提一下，大多时候，是使用sillytavern预设模式以及sillytavern后端模式。\n使用的模型基本也都是flash以及pro。\n\n\n通用提示:\n如果遇到 429 错误，说明API请求过于频繁或负载已饱和，请稍后再试或更换节点/API。\n如果遇到 500 或 PROHIBITED_CONTENT 错误，通常是“破限失败”，即内容被模型服务商的安全策略拦截。可以尝试更换模型（如DSv3的“甲比较薄”），或在插件的“提示词编辑器”（左下角魔法棒）中修改、增强破限提示词。\n\nQ2: 插件的测试按钮提示失败，但实际功能可用？\n\nA: 插件早期版本的测试按钮存在问题，可能无法正确反映API连通性。请以实际功能（如优化、总结）是否能正常使用为准。\n\n总结功能\nQ3: “小总结” 和 “大总结” 有什么区别？\n\nA: 两者是递进关系：\n小总结 (微言录)：在后台根据您设定的消息阈值（如每30条）自动进行，生成较为详细的剧情摘要。\n大总结 (宏史卷)：当小总结内容过多（如超过20000字符）时，通过手动点击“史册精炼”按钮，对已生成的小总结进行二次提炼和压缩，以节省Token。\n\nQ4: 我开了新聊天或走了不同的剧情分支，为什么总结内容会和之前的混在一起？\n\nA: 插件是通过 世界书名称 和 条目名称 (【敕史局】对话流水总账) 来识别和续写总结的。为了区分不同聊天或分支的总结，您可以：\n找到旧总结所在的世界书条目。\n修改其名称，例如在前面加上“分支A - ”。\n这样插件在新的聊天中就会创建一个全新的总结条目，而不会与旧的混淆。\n当您想继续玩旧分支时，只需将条目名称改回去即可。\n\nQ5: 总结生成的世界书，应该如何使用？\n\nA: 强烈建议将总结用的世界书 关联到角色卡，而不是设为全局。\n在插件设置中，选择 “写入位置” 为 “独立档案”。这会自动创建一个以 Amily2-Lore-角色卡名 命名的独立世界书。\n进入角色卡编辑页面，在 “更多选项” 中找到 “附加知识书”，将这个新建的世界书链接进去。\n在世界书管理页面，为该总结条目设置 蓝灯常驻，并可根据需要调整注入深度（推荐深度1或2，使其独立于其他世界书）。\n\nQ6: 总结中断或部分楼层失败了怎么办？\n\nA: 如果“开始远征”过程中断，可以手动补救：\n在“微言录”功能区，使用“手动熔铸”功能，选择失败的楼层范围（如 250-300）进行单独总结。\n将成功总结的内容，手动复制粘贴到主总结条目的对应位置。\n注意：操作前请一定备份好您的世界书，并确保 本条勿动【前X楼总结已完成】... 这句“金印”的楼层数是正确的。\n\n正文优化\nQ7: 正文优化功能似乎没效果，或者把我的角色卡格式弄乱了？\n\nA: 这是因为优化功能依赖对 正文标签 的识别。\n确认标签：您需要通过“编辑消息”功能（小铅笔图标）查看AI回复的原文，找到包裹主要叙事内容的标签，例如 <content>、<dream> 或 <plot>。\n正确填写：将这个标签名（不需要尖括号）填入插件主殿的 “御定优化标签” 输入框中。\n格式兼容性：如果您的角色卡或预设在正文标签内嵌套了其他复杂格式（如状态栏、美化标签），可能会导致优化后格式丢失。开发者正在努力改进这一点。对于纯文字卡或格式简单的卡，优化效果最佳。\n\nQ8: 如何对比优化前后的效果？\n\nA: 有两种方式：\nPC端: 按 F12 打开浏览器控制台，在日志中可以找到 \"Amily2优化任务\" 的记录。“发往ai” 中的是原始文本，“原始回复” 是优化后的文本。\n插件内置查看器: 在左下角扩展菜单中开启“查看优化前文”，会出现一个可拖动的按钮，点击即可查看最近一次的优化原文。\n\n其他功能\nQ9: “隐藏楼层”功能为什么没让聊天记录消失？\n\nA: 本插件的“隐藏楼层”功能，作用是 不将这部分楼层的内容发送给AI，从而节省上下文Token，提高AI的注意力。它并 不会 在您的聊天界面上隐藏这些消息。如果您需要折叠界面上的聊天记录，请使用SillyTavern自带的设置（通常在顶部栏的 “格式” 或 “UI” 设置中）。\n\nQ10: 翰林院 (RAG/向量化) 是什么？怎么用？\n\nA: 这是一个用于实现 超长期记忆 的高级功能。\n原理：将大量文本（如小说、详细背景设定、过往总结）转换为AI能快速检索的“向量坐标”。当您聊天时，它会自动找出与当前对话最相关的内容片段并发送给AI。\n专用API：它需要使用专门的 嵌入式模型 (Embedding Model) API，不能使用您平时的聊天模型API。\n推荐服务：您可以在 硅基流动 (SiliconFlow) 等平台注册并获取免费额度的嵌入式模型API。\n使用：在插件“翰林院”页面配置好API，然后即可将小说、世界书条目或聊天记录进行“凝识”（即向量化），之后在“忆识检索”中开启总开关即可在聊天中自动生效。\n\nQ11: 安装/更新插件后，界面上找不到插件按钮了？\n\nA: 这通常是开发者上传文件时偶尔遗漏导致的。解决方法是 卸载并重装插件。请在SillyTavern的 extensions 文件夹中删除本插件目录，然后通过GitHub链接重新安装。\n\nQ12: 授权码无效怎么办？\n\nA: 请先更新到最新版插件。新版本在打开插件页面时，会自动生成一个当日有效的授权码，复制粘贴即可。\n\nQ12: 预设导入错误怎么办？\nA：木悠版本的表格预设不适配于Amily2号插件。\nB：Amily2号基本不需要预设，想要什么表自己加就行了，十分方便。",
                "constant": true,
                "selective": true,
                "insertion_order": 100,
                "enabled": true,
                "position": "after_char",
                "use_regex": true,
                "extensions": {
                    "position": 4,
                    "exclude_recursion": false,
                    "display_index": 13,
                    "probability": 100,
                    "useProbability": true,
                    "depth": 14,
                    "selectiveLogic": 0,
                    "group": "",
                    "group_override": false,
                    "group_weight": 100,
                    "prevent_recursion": false,
                    "delay_until_recursion": false,
                    "scan_depth": null,
                    "match_whole_words": null,
                    "use_group_scoring": false,
                    "case_sensitive": null,
                    "automation_id": "",
                    "role": 0,
                    "vectorized": false,
                    "sticky": 0,
                    "cooldown": 0,
                    "delay": 0,
                    "match_persona_description": false,
                    "match_character_description": false,
                    "match_character_personality": false,
                    "match_character_depth_prompt": false,
                    "match_scenario": false,
                    "match_creator_notes": false
                }
            }
        ],
        "name": "Amily2答疑"
    }
}